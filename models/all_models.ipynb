{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.telenor.rs/media/TelenorSrbija/media/Telenor_horizontalni.jpg\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "<h1><center>TELENOR DIGITAL: SMARTE BYGG</center></h1>\n",
    "<h2><center> Summer project 2019 </center><h2>\n",
    "<h4><center> By Maria Hilmo Jensen, May Helen Storvik and Odd Eirik Igland </center><h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The main purpose of this project is to predict how many people that will come in to work at Telenor Fornebu for up to approximatly one week into the future. We were provided with data about the number of transactions made in the canteens, as well as parking information for the time period October 2016 to February 2019. Since this was the only available data, we assumed that the number of people at work are equal to the amount that eats in the canteens. The data set did not contain information about the canteen transactions for all the dates between the start date and end date, so based on the parking information we could assume how many people were at Telenor also when we were missing data about the canteen. We also decided to consider outside parameters, such as temperature, precipitation, vacations, holidays, day of the week and time of year. We also simply assumed that no one is here in the weekends, so all the canteen data for weekends were set to zero. \n",
    "\n",
    "The team decided to test several different prediction models to find the one performing the best. The models we used were:\n",
    "* Linear regression\n",
    "* Simple time series model with Naive Bayes\n",
    "* Facebook Prophet for time series analysis\n",
    "* Feed Forward Neural Network\n",
    "* Catboost Decision Tree\n",
    "* LSTM Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "All the necessary packages and files are imported here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.abspath(''), os.path.pardir)))\n",
    "\n",
    "from all_models import *\n",
    "from helpers.helpers import plot_history_df, plot_history, load_model, plot_prediction, plot_history_and_prediction_df, plot_history_and_prediction_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Data Analysis\n",
    "The team were provided with raw canteen transaction data and parking data from Telenor. This part is about understanding the provided data and collecting more data from external APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parking and canteen data\n",
    "parking_and_canteen.py: \n",
    "* Combinding the raw data from parking and canteen transactions.\n",
    "* Finding the correlation between parking and canteen\n",
    "* Removing outliers\n",
    "* Fill in missing canteen data based on parking\n",
    "\n",
    "### Coorelation\n",
    "Describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_correlation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display data\n",
    "Plots the canteen data for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_canteen_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weather\n",
    "weather.py:\n",
    "* Historic weather data are collected from the [Frost API](https://frost.met.no/index.html) provided by Meterologisk Institutt.\n",
    "* Using the weather station at Blindern (no. SN18700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holidays and vacation\n",
    "holiday.py:\n",
    "* Historic holiday data are collected from [WebAPI](https://webapi.no/api/v1/holidays/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination\n",
    "combined_dataset.py:\n",
    "* Merges the combined canteen/parking data with weather data and holidays/vacation/inneklemt\n",
    "* Stores the created dataframe into a .csv file in the data folder: dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/dataset.csv', index_col='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data in the file looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Preprocessing\n",
    "After the raw data files are combined into dataset.csv, the data needs to be preprocessed further before they are used by the models. All preprocessing methods are found in the preprocessing folder and are summarized in two methods in preprocessing.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including historic canteen data \n",
    "The team decided to add historic canteen data as columns to the data file because of the strong correlation between these numbers. This includes the number of canteen transactions made one week ago and the previous day.\n",
    "\n",
    "The following plots shows the relation between these numbers for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Including weekday and time of the year\n",
    "We were also interested in finding the effect of the day of the week and time of year. Two colums were therefore added, one displaying the weekday and one variable with distance from start of the year (as a number between 0 and 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorizing the temperature\n",
    "The original data contained both maximum and minimum temperature. It was decided to combine these to one column by taking the average of the two values. We made the assumption that temperatures in spesicic intervals increases the probability that people stay home from work. Therefore, we categorized the average temperatures into two groups; Temperatures where you are more likely to skip work (stay_home_temp) and temperatures were you most likely go to work (preferred_work_temp). We assumed that very low temperatures (less than -10 degrees), temperatures around 0 degrees (from -2 to +2 degrees) and temperatures above +20 degrees are more likely to affect if people come to work, and these interval were therefore chosen to be our stay_home_temp. All other temperatures are preferred_working_temp. \n",
    "\n",
    "-10 <= x <= -2 || +2 <= x <= 20 (preferred_work_temp),\n",
    "x < -10 || -2 < x < +2 || x > 20 (stay_home_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resulting data format\n",
    "After the previously mentioned preprocessing steps were taken, it was necessary to create two different input data formats. The reason for this is that the machine learning models consider weighted inputs and the categories for each column are therefore used as new columns. All the other models can use the previously created format (now named decision tree dataframe).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the main_file.py file, all necessary files are being added to the data folder. This includes all the preprocessing steps and stores two new data files named decision_tree_df.csv and ml_df.csv in the data folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data files\n",
    "After the new files are created they can be loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_df, ml_df = load_datafiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top five rows of the decision tree and machine learning data sets are shown respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "Throughout this summer the team has worked on several different prediction models, both statistical and machine learning models. All the models, explaination and visualizations are presented below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "Linear regression is a linear approach to modeling the relationship between two variables. The linear() function uses the inputs date and historic canteen values in order to predict future values. \n",
    "\n",
    "A model using linear regression will try to draw a straight line that will minimize the residual sum of squares between the observed responses in the dataset. (Source: https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, y_pred, x_test, y_test = linear(dataset) \n",
    "plot_linear(x, y, x_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our canteen data fluctuates a straight line will not manage to create a good prediction of future values as can be seen in the graph above. The mean absolute error of the linear regression model is usually around 800 people. \n",
    "\n",
    "The model performs slightly better if weekends are removed from the dataset, but the result is still not sufficient compared to the other models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple time series with Naive Bayes for forecasting\n",
    "This model takes advantage of one approach that is commonly known as binning (discretization or reducing the scale level of a random variable from numerical to categorical). An advantage of this technique is the reduction of noise - however, this comes at the cost of losing quite an amount of information.\n",
    "\n",
    "This model only considers the canteen data as a function of time (date)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_time_series(dt_df, 30, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph displays the real canteen values and the predicted canteen values for the data set. As we can see the prediction can discover some of the trends in the data set, but fails to detect the decreasing trend over time. The mean absolute error for this model is 181.15 people, which is quite high but still a major improvement compared to the linear regression. \n",
    "\n",
    "Since this is a time series model, it is made for predicting the values directly following the data set it is provided. Therefore, when this model are going to predict the future, it has to predict every day between the last day in the data set and today before it can come up with a prediction for future dates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facebook Prophet\n",
    "Prophet is designed for analyzing time series with daily observations that display patterns on different time scales. Prophet is robust to missing data and shifts in the trend, and typically handles outliers well. It also has advanced capabilities for modeling the effects of holidays on a time-series.\n",
    "\n",
    "Also this model only considers the canteen data and date, as well as Norwegian holidays (provided by Prophet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prophet(dt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot displays the prediction made by Prohpet. The black dots represents the real values, the dark blue lines is the predictions and the light blue lines are a 95 % confidence interval for the predictions. As we can see, the model fits some of the data points and are able to detect trends from holidays. The MAE for this model is 69.91 people, which is a great improvement to the simple time series model. The model performs surprisingly well for only considering people over time and holidays. \n",
    "\n",
    "A major drawback to this model is that it has to predict the values directy following the data set, in the same way the simple time series model works. This implies that in order to perform well the model require recent canteen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_and_prediction_ml(\n",
    "    load_model(\"feed_forward_history\"),\n",
    "    load_model(\"feed_forward_epoch\"),\n",
    "    load_model(\"feed_forward_test_set_prediction\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history_and_prediction_df(\n",
    "    load_model(\"catboost_evaluation_result\"), \n",
    "    load_model(\"catboost_test_set_prediction\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model was made using a recurrent neural network with LSTM (Long Short Term Memory). The model was made using tensorflow, which provides a high level API called keras for modeling and training of neural networks. \n",
    "\n",
    "The model input includes all relevant external factors that might affect the amount of people that go to work a given day in the near future. All input is scaled to be in the range of 0 to 1. \n",
    "\n",
    "Models with a Mean Absolute Error (MAE) score of less than 40 is stored in lstm_model.h5, so that it is easy to reuse the model and its weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(load_model(\"lstm_history\"), load_model(\"lstm_epoch\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph above displays the result of a trained model (test dataset size=8) with a MAE score of less than 40, this can of course be changed to a lower or higher number as needed. The model's MAE usually differs with the test dataset size, so if you have a test dataset of size 175 then a good MAE score is usua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the models\n",
    "All the different models are compared based on how they perform on predicting the last given number days of our dataset, as well as 8 days into the future (from today).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data from data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create test dataframe for model comparison\n",
    "All the models will be tested against the last given number of days of the full data set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 8\n",
    "\n",
    "real_canteen, dt_df_test = create_dataframe_for_comparison(dt_df, test_size)\n",
    "_, ml_df_test = create_dataframe_for_comparison(ml_df, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree test dataframe looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the predictions\n",
    "The following table displays the predictions from all the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = create_predictions(dt_df, ml_df, dt_df_test, ml_df_test, False, real_canteen)\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the predictions against the real values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_test_predictions(merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, Catboost and LSTM are the models predicting most correctly. The simple time series model with Naive Bayes performs most poorly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting the future\n",
    "We start by getting the data sets for the next days. These sets are created with the same format as the test data sets from the previous section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_next, ml_next = load_next_days()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataframe for decision trees looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_merged = create_predictions(dt_df, ml_df, dt_next, ml_next, True)\n",
    "future_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_test_predictions(future_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the figure above, the prediction results vary greatly among the different models but it appears as if Catboost and LSTM still provides the most likely results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the achieved results, we would recommend to use either the Catboost or LSTM model. \n",
    "\n",
    "\n",
    "Next steps:\n",
    "* Update daily with new data to provide a stronger prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
